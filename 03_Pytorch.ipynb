{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tenseurs\n",
        "\n",
        "Les tenseurs sont une structure de données spécialisée très similaire aux tableaux et aux matrices.\n",
        "Dans PyTorch, nous utilisons les tenseurs pour coder les entrées et les sorties d'un modèle, ainsi que les paramètres du modèle.\n",
        "\n",
        "\n",
        "Les tenseurs sont similaires aux tableaux `NumPy` et aux `ndarrays`, sauf que les tenseurs peuvent fonctionner sur des GPUs ou d'autres accélérateurs matériels. En fait, les tenseurs et les tableaux NumPy peuvent souvent partager la même adresse mémoire sous-jacente avec une capacité appelée `bridge-to-np-label`, ce qui élimine le besoin de copier les données. Les tenseurs sont également optimisés pour la différenciation automatique (nous verrons cela plus tard ). Si vous êtes familier avec les `ndarrays`, vous serez à l'aise avec l'API des tenseurs.\n",
        "\n",
        "Commençons par mettre en place notre environnement."
      ],
      "metadata": {
        "id": "oRHLTQoOaFjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5v0sv3tnaOYD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialisation d'un tenseur\n",
        "\n",
        "Les tenseurs peuvent être initialisés de différentes manières. Regardez les exemples suivants.\n",
        "\n",
        "## Directement à partir de données\n",
        "\n",
        "Les tenseurs peuvent être créés directement à partir de données. Le type de données est automatiquement déduit."
      ],
      "metadata": {
        "id": "DROBQZ9BaFf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "x_data"
      ],
      "metadata": {
        "id": "KKPvGWfLaeCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ebb833e-028c-46dd-881c-9a389b8927ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2],\n",
              "        [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A partir d'un tableau NumPy\n",
        "\n",
        "Les tenseurs peuvent être créés à partir de tableaux NumPy et vice versa.  Puisque numpy _'np_array'_ et tensor _'x_np'_ partagent le même emplacement mémoire, changer la valeur de l'un modifiera l'autre."
      ],
      "metadata": {
        "id": "soc2NKc-aFc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "\n",
        "print(f\"Numpy np_array value: \\n {np_array} \\n\")\n",
        "print(f\"Tensor x_np value: \\n {x_np} \\n\")\n",
        "\n",
        "np.multiply(np_array, 2, out=np_array)\n",
        "\n",
        "print(f\"Numpy np_array after * 2 operation: \\n {np_array} \\n\")\n",
        "print(f\"Tensor x_np value after modifying numpy array: \\n {x_np} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KglHGVnaq4G",
        "outputId": "67f463fd-433c-4819-9aed-21e54cf3180e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy np_array value: \n",
            " [[1 2]\n",
            " [3 4]] \n",
            "\n",
            "Tensor x_np value: \n",
            " tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "Numpy np_array after * 2 operation: \n",
            " [[2 4]\n",
            " [6 8]] \n",
            "\n",
            "Tensor x_np value after modifying numpy array: \n",
            " tensor([[2, 4],\n",
            "        [6, 8]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A partir d'un autre tenseur\n",
        "\n",
        "Le nouveau tenseur conserve les propriétés (forme, type de données) du tenseur argument, à moins qu'il ne soit explicitement remplacé."
      ],
      "metadata": {
        "id": "mDdYip99aFaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lovdJOFNa3co",
        "outputId": "e1b0ca74-e001-4778-8515-be2cf102240e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.7243, 0.7732],\n",
            "        [0.2601, 0.2174]]) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avec des valeurs aléatoires ou constantes\n",
        "\n",
        "`shape` est défini par un tuple de dimensions de tenseur, qui définit le nombre de lignes et de colonnes dans un tenseur. Dans les fonctions ci-dessous, `shape` détermine la dimensionnalité du tenseur de sortie."
      ],
      "metadata": {
        "id": "S8W-t7PDaEve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2,3)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCFoqsSTbAcQ",
        "outputId": "6de3ab6a-dc0b-40ee-fd14-89ece5734023"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.8015, 0.1767, 0.6034],\n",
            "        [0.4992, 0.0036, 0.9915]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attributs d'un tenseur\n",
        "\n",
        "Les attributs d'un tenseur décrivent sa forme, son type de données et le dispositif sur lequel il est stocké."
      ],
      "metadata": {
        "id": "7s9mn2wZbMu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z58t0mGkbLux",
        "outputId": "ace1463d-d747-41f0-b357-8248c641f45f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Opérations sur les tenseurs\n",
        "\n",
        "Il existe plus de 100 opérations sur les tenseurs, y compris l'arithmétique, l'algèbre linéaire, la manipulation de matrices (comme la transposition, l'indexation et le découpage). Pour l'échantillonnage et l'examen, vous trouverez une description complète [ici](https://pytorch.org/docs/stable/torch.html).\n",
        "\n",
        "Chacune de ces opérations peut être exécutée sur le GPU (à des vitesses généralement plus élevées que sur un\n",
        "CPU).\n",
        "- Les CPU ont jusqu'à 64 cœurs. Les cœurs sont des unités qui effectuent le calcul proprement dit. Chaque cœur traite les tâches dans un ordre séquentiel (une tâche à la fois).\n",
        "- Les GPU ont des milliers de cœurs.  Les cœurs des GPU effectuent des calculs en parallèle. Les tâches sont réparties et traitées entre les différents cœurs. C'est ce qui rend les GPU plus rapides que les CPU dans la plupart des cas. Les GPU sont plus performants pour les données de grande taille que pour les données de petite taille. Les GPU sont généralement utilisés pour les calculs intensifs de graphiques ou de réseaux neuronaux.\n",
        "- PyTorch peut utiliser la bibliothèque Nvidia CUDA pour tirer parti de leurs cartes GPU.\n",
        "\n",
        "\n",
        "Par défaut, les tenseurs sont créés sur le CPU. Les tenseurs peuvent également être calculés sur des GPUs ; pour cela, vous devez les déplacer en utilisant la méthode `.to` (après avoir vérifié la disponibilité des GPUs). Gardez à l'esprit que la copie de tenseurs de grande taille sur différents périphériques peut être coûteuse en termes de temps et de mémoire !"
      ],
      "metadata": {
        "id": "875oB1Cva5za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')"
      ],
      "metadata": {
        "id": "jLvADlg1beJX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essayez certaines des opérations de la liste.\n",
        "Si vous êtes familier avec l'API NumPy, vous trouverez l'API Tensor très facile à utiliser.\n",
        "\n",
        "## Indexation et découpage standard de type NumPy"
      ],
      "metadata": {
        "id": "Icytxjrsa5wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print('First row: ',tensor[0])\n",
        "print('First column: ', tensor[:, 0])\n",
        "print('Last column:', tensor[..., -1])\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47s-_w8JbquM",
        "outputId": "55852152-5b76-4e74-beb8-9572ebcf2c26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Joindre des tenseurs\n",
        "Vous pouvez utiliser [`torch.cat`](https://pytorch.org/docs/stable/generated/torch.cat.html) pour concaténer une séquence de tenseurs le long d'une *dimension donnée*.\n",
        "[`torch.stack`](https://pytorch.org/docs/stable/generated/torch.stack.html) est une option connexe de jonction de tenseurs qui concatène une séquence de tenseurs le long d'une *nouvelle* dimension."
      ],
      "metadata": {
        "id": "KTLluR4Oa5tT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwZg2-DPb0Je",
        "outputId": "7e419c00-ecbb-4916-d92b-dfad14547461"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opérations arithmétiques"
      ],
      "metadata": {
        "id": "5AwLj99Ta5qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(tensor)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4B81pwVb8Nl",
        "outputId": "f8f441e1-8718-4c7f-9121-11d85c499fa8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tenseurs à un seul élément\n",
        "Si vous avez un tenseur à un élément, par exemple en agrégeant toutes les valeurs d'un tenseur en une seule valeur, vous pouvez le convertir en valeur numérique Python\n",
        "en utilisant `item()` :"
      ],
      "metadata": {
        "id": "kddK-cNoa5n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg = tensor.sum()\n",
        "agg_item = agg.item()\n",
        "print(agg_item, type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onfL5nOGcEzm",
        "outputId": "d833a105-ac3a-4d0d-90ae-474a29faa161"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opérations sur place\n",
        "Les opérations qui stockent le résultat dans l'opérande sont appelées \"in-place\". Elles sont désignées par un suffixe ``_``.\n",
        "Par exemple : ``x.copy_(y)``, ``x.t_()``, changeront ``x``.\n",
        "\n",
        ">**Note:** Les opérations in-place permettent d'économiser de la mémoire, mais peuvent être problématiques lors du calcul des dérivées à cause de la perte immédiate de l'historique. Leur utilisation est donc déconseillée."
      ],
      "metadata": {
        "id": "H9UePLCoa5lE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww4kONLBcOkF",
        "outputId": "4a1f84cf-d7c7-4cb0-eae6-f0fa3cedc553"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pont avec NumPy\n",
        "\n",
        "Les tenseurs sur le CPU et les tableaux NumPy peuvent partager leurs emplacements mémoire sous-jacents, et la modification de l'un modifiera l'autre.\n",
        "\n",
        "### Tenseur vers tableau NumPy"
      ],
      "metadata": {
        "id": "yedjJvIGa5iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oo4WNjnmcXYp",
        "outputId": "7c83c9b1-d550-4228-e0fd-4664a32acbae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwjiYpjzcfvo",
        "outputId": "adc5b76a-aef6-4565-d8ce-ac8cbac8cf58"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un changement dans le tenseur se reflète dans le tableau NumPy."
      ],
      "metadata": {
        "id": "Xs2fclRaa5fY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NumPy array à tensor"
      ],
      "metadata": {
        "id": "7co2YwQva5ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "metadata": {
        "id": "Y9xyjs-mcpDv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les changements dans le tableau NumPy se reflètent dans le tenseur."
      ],
      "metadata": {
        "id": "7LI6FOsPa5Zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAHKGOiAc1Mm",
        "outputId": "218433ca-ae76-4a2a-f55e-620281aa5078"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets et Dataloaders\n",
        "\n",
        "Le code de traitement des échantillons de données peut devenir complexe et difficile à maintenir. Nous souhaitons généralement que le code de nos ensembles de données soit découplé du code d'apprentissage de nos modèles, pour une meilleure lisibilité et modularité.\n",
        "PyTorch fournit deux primitives de données : ``torch.utils.data.DataLoader`` et ``torch.utils.data.Dataset``\n",
        "qui vous permettent d'utiliser des jeux de données pré-chargés ainsi que vos propres données.\n",
        "``Dataset`` stocke les échantillons et leurs étiquettes correspondantes, et ``DataLoader`` enroule un itérable autour de ``Dataset`` pour permettre un accès facile aux échantillons.\n",
        "\n",
        "Les bibliothèques de domaine PyTorch fournissent un certain nombre de jeux de données pré-chargés (comme **_FashionMNIST_**) qui sous-classent ``torch.utils.data.Dataset`` et implémentent des fonctions spécifiques aux données particulières. Les exemples pour le prototypage et l'évaluation de votre modèle incluent :\n",
        "- Jeux de données d'images\n",
        "- Jeux de données texte\n",
        "- Jeux de données audio\n",
        "\n",
        "## Chargement d'un jeu de données\n",
        "\n",
        "Nous allons charger le jeu de données Fashion-MNIST de TorchVision. Fashion-MNIST est un jeu de données d'images d'articles de Zalando composé de 60 000 exemples d'entraînement et de 10 000 exemples de test.  Chaque exemple comprend une image en niveaux de gris de 28×28 et une étiquette associée à l'une des 10 classes.  \n",
        "\n",
        " - Chaque image a une hauteur de 28 pixels et une largeur de 28 pixels, soit un total de 784 pixels\n",
        " - Les 10 classes indiquent de quel type d'image il s'agit, par exemple : T-shirt/top, pantalon, pull-over, robe, sac, botte de cheville, etc.\n",
        " - Les pixels en niveaux de gris ont des valeurs comprises entre 0 et 255 qui mesurent l'intensité des images en noir et blanc.  La valeur de l'intensité augmente du blanc au noir. Par exemple : une couleur blanche vaut 0, tandis qu'une couleur noire vaut 255.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Nous chargeons l'ensemble de données FashionMNIST avec les paramètres suivants :\n",
        " - **root** est le chemin d'accès où les données d'entraînement et de test sont stockées.\n",
        " - **train** spécifie l'ensemble de données d'entraînement ou de test.\n",
        " - **download=True** télécharge les données à partir d'Internet si elles ne sont pas disponibles à la racine.\n",
        " - **transform** et `target_transform` spécifient les transformations des caractéristiques et des étiquettes."
      ],
      "metadata": {
        "id": "Ww8KrzIPa5Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9rEg8oOdEqw",
        "outputId": "7d346b3f-a0fa-4e54-90e4-8e31f8b563ac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 10326444.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 174706.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3215734.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 19024032.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Itération et visualisation de l'ensemble de données\n",
        "-----------------\n",
        "\n",
        "Nous pouvons indexer ``Datasets`` manuellement comme une liste : ``training_data[index]``.\n",
        "Nous utilisons ``matplotlib`` pour visualiser certains échantillons de nos données d'entraînement."
      ],
      "metadata": {
        "id": "uxKJMECCa5UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "QzU2fsuAdTa-",
        "outputId": "aeb98f49-0c7e-4e6d-ca98-d153e79c7e3e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Préparer vos données pour l'entrainement avec DataLoaders\n",
        "-------------------------------------------------\n",
        "Le ``Dataset`` récupère les caractéristiques et les étiquettes de notre jeu de données, un échantillon à la fois. Lors de l'apprentissage d'un modèle, nous voulons typiquement\n",
        "passer les échantillons en \"minibatchs\", remanier les données à chaque epoch pour réduire le surajustement du modèle, et utiliser le multiprocessing de Python pour accélérer la récupération des données.\n",
        "\n",
        "En apprentissage automatique, vous devez spécifier les caractéristiques et les étiquettes de votre ensemble de données. Les **caractéristiques** sont des données d'entrée et les **étiquettes** sont des données de sortie.\n",
        "\n",
        "  - Les caractéristiques sont les motifs des pixels des images\n",
        "  - Les étiquettes sont nos 10 types de classes :  T-shirt, Sandale, Robe, etc\n",
        "\n",
        "Le ``DataLoader`` est un itérable qui abstrait cette complexité pour nous dans une API plus simple. Pour utiliser le Dataloader, nous devons définir les paramètres suivants :\n",
        "\n",
        " - **data** les données d'entraînement qui seront utilisées pour entraîner le modèle, et les données de test pour évaluer le modèle\n",
        " - **batch_size**  : le nombre d'enregistrements à traiter dans chaque lot.\n",
        " - **shuffle** l'échantillonage aléatoire des données par indices"
      ],
      "metadata": {
        "id": "H6aiPEW8a5RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "pGa_CGQ_dpb5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Itérer à travers le DataLoader\n",
        "\n",
        "Nous avons chargé ce jeu de données dans le `Dataloader` et nous pouvons maintenant itérer à travers le jeu de données.\n",
        "Chaque itération ci-dessous retourne un batch de `train_features` et `train_labels` (contenant respectivement `batch_size=64` features et labels). Parce que nous avons spécifié `shuffle=True`, après avoir itéré sur tous les lots, les données sont mélangées, pour un contrôle plus fin sur l'ordre de chargement des données."
      ],
      "metadata": {
        "id": "I5j1hWNta5OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "label_name = list(labels_map.values())[label]\n",
        "print(f\"Label: {label_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "Yk-4nbVYdzjZ",
        "outputId": "4a2029c5-3097-4343-9223-0130ad0539da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: Sneaker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalisation\n",
        "\n",
        "La normalisation est une technique courante de prétraitement des données qui est appliquée pour mettre à l'échelle ou transformer les données afin de s'assurer que chaque caractéristique apporte une contribution égale à l'apprentissage. Par exemple, chaque pixel des images en niveaux de gris a une valeur comprise entre 0 et 255, qui sont des caractéristiques. Si la valeur d'un pixel est de 17 et celle d'un autre de 197. Il y aura une distribution inégale de l'importance des pixels, car les volumes de pixels les plus élevés dévieront l'apprentissage. La normalisation modifie l'étendue de vos données, sans fausser la distinction entre nos caractéristiques. Ce prétraitement est effectué pour éviter :\n",
        "\n",
        "- une réduction de la précision de la prédiction\n",
        "- une difficulté d'apprentissage pour le modèle\n",
        "- Une distribution défavorable des plages de données des caractéristiques"
      ],
      "metadata": {
        "id": "5IwWhz9Za5LO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformations\n",
        "\n",
        "Les données ne se présentent pas toujours sous la forme traitée finale requise pour\n",
        "pour l'apprentissage des algorithmes d'apprentissage automatique. Nous utilisons des **transformations** pour manipuler les données et les rendre aptes à l'apprentissage.\n",
        "\n",
        "Tous les jeux de données de TorchVision ont deux paramètres (`transform` pour modifier les caractéristiques et\n",
        "`target_transform` pour modifier les étiquettes) qui acceptent des callables contenant la logique de transformation. Le module `torchvision.transforms` offre plusieurs\n",
        "plusieurs transformations couramment utilisées.\n",
        "\n",
        "Les caractéristiques FashionMNIST sont au format PIL Image, et les étiquettes sont des entiers.\n",
        "Pour l'entraînement, nous avons besoin des caractéristiques sous forme de tenseurs normalisés, et des étiquettes sous forme de tenseurs codés à une position.\n",
        "Pour effectuer ces transformations, nous utiliserons `ToTensor` et `Lambda`."
      ],
      "metadata": {
        "id": "Q34sw9b4a5IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "ds = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
        ")"
      ],
      "metadata": {
        "id": "NdsWbWxFeDwl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ToTensor()\n",
        "\n",
        "`ToTensor` convertit une image PIL ou un `ndarray` NumPy en un `FloatTensor` et met à l'échelle les valeurs d'intensité des pixels de l'image dans l'intervalle \\[0., 1.\\].\n",
        "\n",
        "## Transformations lambda\n",
        "\n",
        "Les transformations lambda appliquent n'importe quelle fonction lambda définie par l'utilisateur. Ici, nous définissons une fonction\n",
        "pour transformer l'entier en un tenseur codé en un seul point.\n",
        "Elle crée d'abord un tenseur zéro de taille 10 (le nombre d'étiquettes dans notre jeu de données) et appelle scatter qui attribue une valeur de\n",
        "1 à l'index donné par l'étiquette _y_. Vous pouvez aussi utiliser `torch.nn.functional.one_hot` comme autre option pour faire cela."
      ],
      "metadata": {
        "id": "tDESE4U8a5FR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_transform = Lambda(lambda y: torch.zeros(\n",
        "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))"
      ],
      "metadata": {
        "id": "N1_VNQUHeNPe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Qu'est-ce qu'un réseau neuronal ?\n",
        "\n",
        "Un réseau neuronal est un ensemble de **neurones** reliés par des couches. Chaque neurone est une petite\n",
        "unité de calcul qui effectue des calculs simples pour résoudre collectivement un problème. Les neurones sont\n",
        "organisés en 3 types de couches : la couche d'entrée, la couche cachée et la couche de sortie.\n",
        "Les couches cachées et de sortie contiennent un certain nombre de neurones.\n"
      ],
      "metadata": {
        "id": "lUvO0Aw6eBVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Composants d'un réseau neuronal\n",
        "\n",
        "- Une **fonction d'activation** détermine si un neurone doit être activé ou non. Les calculs effectués dans un réseau neuronal comprennent l'application d'une fonction d'activation. Si un neurone s'active, cela signifie que l'entrée est importante. Il existe différents types de fonctions d'activation. Le choix de la fonction d'activation à utiliser dépend de la nature de la sortie. Un autre rôle important d'une fonction d'activation est d'ajouter de la non-linéarité au modèle.\n",
        "\n",
        "    - La fonction _Binary_ est utilisée pour mettre un nœud de sortie à 1 si le résultat de la fonction est positif et à 0 si le résultat de la fonction est nul ou négatif. f(x)= \\begin{cases} 0, & \\text{if } x < 0\\\\ 1, & \\text{if } x\\geq 0\\\\ \\end{cases}\n",
        "    - _Sigmoïde_ est utilisé pour prédire la probabilité qu'un nœud de sortie soit compris entre 0 et 1. $f(x) = {\\large \\frac{1}{1+e^{-x}}}$\n",
        "    - _Tanh_ est utilisé pour prédire si un nœud de sortie est compris entre 1 et -1, pour les cas d'utilisation de la classification. $f(x) = {\\large \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}} $\n",
        "    - La _ReLU_ (*fonction d'activation linéaire rectifiée*) est utilisée pour mettre le nœud de sortie à 0 si le résultat de la fonction est négatif et conserve la valeur du résultat si celui-ci est positif. f(x)= \\begin{cases} 0, & \\text{if } x < 0\\\\ x, & \\text{if } x\\geq 0\\\\ \\end{cases}\n",
        "- Les **poids** influencent la proximité de la sortie de notre réseau par rapport à la valeur de sortie attendue. Lorsqu'une entrée entre dans le neurone, elle est multipliée par une valeur de poids et la sortie résultante est soit observée, soit transmise à la couche suivante du réseau neuronal. Les poids de tous les neurones d'une couche sont organisés en un tenseur.\n",
        "- Le **biais** représente la différence entre la sortie de la fonction d'activation et la sortie prévue.\n",
        "\n",
        "\n",
        "\n",
        "Nous pouvons dire qu'une sortie $y$ d'une couche de réseau neuronal avec des poids $W$ et un biais $b$ est calculée comme la somme des entrées multipliées par les poids plus le biais. $x = \\sum{(poids * entrées) + biais} $, où $f(x)$ est la fonction d'activation."
      ],
      "metadata": {
        "id": "vSTfbNNHeBSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construire un réseau neuronal\n",
        "\n",
        "Les réseaux neuronaux sont constitués de couches et de modules qui effectuent des opérations sur les données. L'espace de noms `torch.nn` fournit tous les blocs de construction dont vous aurez besoin pour construire votre propre réseau neuronal. Chaque module de PyTorch sous-classe `nn.Module`. Un réseau neuronal est lui-même un module composé d'autres modules (couches). Cette structure imbriquée permet de construire et de gérer facilement des architectures complexes.\n",
        "\n",
        "Dans les sections suivantes, nous allons construire un réseau neuronal pour classer les images de l'ensemble de données FashionMNIST."
      ],
      "metadata": {
        "id": "dnNGdK60eBP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "jdDMl_-E5GQM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtenir du hardware pour l'entraînement\n",
        "\n",
        "Nous voulons pouvoir entraîner notre modèle sur un accélérateur matériel tel qu'un GPU, s'il est disponible. Vérifions si `torch.cuda` est disponible; si ce n'est pas le cas, nous continuerons à utiliser le CPU."
      ],
      "metadata": {
        "id": "QKuAbWMMeBNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj9kcH3i5Rfb",
        "outputId": "cc364ee5-7f65-4756-8941-aebaec6b6b16"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Définir la classe\n",
        "\n",
        "Nous définissons notre réseau neuronal en sous-classant `nn.Module`, et nous initialisons les couches du réseau neuronal dans `__init__`. Chaque sous-classe de `nn.Module` implémente les opérations sur les données d'entrée dans la méthode `forward`.\n",
        "\n",
        "Notre réseau neuronal se compose des éléments suivants :\n",
        "\n",
        "- La couche d'entrée avec 28x28 ou 784 caractéristiques/pixels.\n",
        "- Le premier module linéaire prend les 784 caractéristiques d'entrée et les transforme en une couche cachée de 512 caractéristiques.\n",
        "- La fonction d'activation ReLU sera appliquée dans la transformation.\n",
        "- Le deuxième module linéaire prend 512 caractéristiques en entrée de la première couche cachée et les transforme en 512 caractéristiques dans la couche cachée suivante.\n",
        "- La fonction d'activation ReLU sera appliquée dans la transformation.\n",
        "- Le troisième module linéaire prend 512 caractéristiques en entrée de la deuxième couche cachée et les transforme en couche de sortie avec 10, qui est le nombre de classes.\n",
        "- La fonction d'activation ReLU sera appliquée dans la transformation."
      ],
      "metadata": {
        "id": "N-SMka5O5XXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "t3m4BGFk5W1L"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous créons une instance de `NeuralNetwork`, nous la déplaçons sur `device` et nous imprimons sa structure.\n",
        "sa structure."
      ],
      "metadata": {
        "id": "XOALi-XMeBLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2RmVKop5p7A",
        "outputId": "13950791-254f-4646-ab3d-391ae4691ee6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour utiliser le modèle, nous lui transmettons les données d'entrée. Cela exécute le `forward` du modèle, ainsi que quelques opérations en arrière-plan. Cependant, n'appelez pas `model.forward()` directement ! L'appel du modèle sur les données d'entrée renvoie un tenseur à 10 dimensions avec les valeurs prédites brutes pour chaque classe.\n",
        "\n",
        "Nous obtenons les densités de prédiction en les passant à travers une instance de `nn.Softmax`."
      ],
      "metadata": {
        "id": "PaUzcI7keBIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqzAwPzn5yHc",
        "outputId": "fd7f5b54-6c49-4c25-f756-2935d2d864c1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([4], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Poids et biais\n",
        "\n",
        "\n",
        "Le module `nn.Linear` initialise aléatoirement les ${weights}$ et ${ bias}$ pour chaque couche et stocke en interne les valeurs dans des Tenseurs."
      ],
      "metadata": {
        "id": "VdLguJ6oeBF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"First Linear weights: {model.linear_relu_stack[0].weight} \\n\")\n",
        "\n",
        "print(f\"First Linear biases: {model.linear_relu_stack[0].bias} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nup24QdV5525",
        "outputId": "eeda95af-abb9-4076-84b3-9c40c3f64204"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Linear weights: Parameter containing:\n",
            "tensor([[-0.0175,  0.0336,  0.0039,  ...,  0.0136,  0.0038,  0.0198],\n",
            "        [-0.0314, -0.0196, -0.0240,  ..., -0.0143, -0.0110, -0.0244],\n",
            "        [-0.0011,  0.0317, -0.0321,  ..., -0.0160, -0.0321, -0.0065],\n",
            "        ...,\n",
            "        [-0.0095,  0.0336, -0.0183,  ..., -0.0221,  0.0251, -0.0029],\n",
            "        [-0.0353,  0.0126,  0.0232,  ..., -0.0260,  0.0151,  0.0217],\n",
            "        [ 0.0082, -0.0139,  0.0212,  ..., -0.0229,  0.0091, -0.0046]],\n",
            "       device='cuda:0', requires_grad=True) \n",
            "\n",
            "First Linear biases: Parameter containing:\n",
            "tensor([-2.4022e-02,  1.0361e-02,  1.6576e-02, -1.3333e-02, -2.4206e-03,\n",
            "         7.5577e-03,  3.3727e-02,  3.0883e-02, -3.2969e-02, -1.3902e-02,\n",
            "        -1.0854e-02,  1.1722e-02, -1.0187e-02, -2.1519e-02, -2.1805e-02,\n",
            "        -3.1644e-02,  1.4266e-02, -1.4623e-02,  1.8836e-02, -1.2628e-02,\n",
            "         9.3002e-03, -3.2353e-02, -5.4218e-03,  2.9240e-03, -2.4175e-02,\n",
            "         1.6056e-02, -1.9283e-02, -1.0349e-02,  6.3722e-03, -3.3704e-02,\n",
            "         2.7591e-02,  2.7102e-03, -3.1607e-02, -1.7107e-02,  7.3008e-03,\n",
            "         2.6844e-02, -1.6695e-02, -2.2164e-02, -3.1920e-02, -2.4984e-02,\n",
            "         1.3781e-03, -1.3640e-03,  2.6375e-02,  1.3851e-02,  3.4693e-02,\n",
            "        -3.3119e-02,  1.4033e-02, -3.1925e-02, -2.3364e-02,  1.2203e-02,\n",
            "         8.1126e-04, -8.7439e-03, -7.1738e-03, -2.3577e-02, -2.3677e-02,\n",
            "         2.3682e-03,  2.9331e-02,  1.0622e-02,  8.3247e-03,  2.2751e-02,\n",
            "         2.1223e-02, -2.9676e-02, -2.5035e-02, -3.0341e-02, -1.0754e-02,\n",
            "        -3.1918e-02,  1.5423e-02, -2.3219e-02,  3.5641e-02, -2.9505e-02,\n",
            "         3.4010e-02, -1.3524e-02, -7.3350e-04, -2.4049e-03, -3.3637e-03,\n",
            "        -2.6028e-03,  1.2672e-02,  6.5553e-03,  2.0462e-02,  9.6735e-03,\n",
            "        -1.7085e-03, -2.6511e-02, -3.2985e-02, -2.4054e-02, -3.5334e-02,\n",
            "         2.5824e-02,  3.4141e-02, -9.3042e-03,  9.7857e-03, -4.9620e-04,\n",
            "        -1.4017e-02, -1.4816e-03, -2.6370e-03, -8.5690e-03,  3.8847e-03,\n",
            "         1.2496e-02,  3.0460e-02, -1.8998e-02, -3.3149e-02,  8.1175e-03,\n",
            "        -9.7726e-03,  1.7368e-02, -3.5542e-02, -1.2108e-02, -2.8579e-02,\n",
            "        -3.2014e-02, -1.7033e-02, -1.3625e-02,  1.0463e-02, -3.4037e-02,\n",
            "         3.0735e-02,  1.0135e-02, -3.3276e-02,  1.0167e-02,  1.5534e-02,\n",
            "         1.7096e-02, -1.0940e-02, -2.6987e-02, -1.5344e-02, -8.1315e-03,\n",
            "         2.0972e-02,  4.8950e-03,  1.0093e-02,  2.2245e-02, -3.2007e-02,\n",
            "        -3.7246e-03,  2.3514e-02,  1.0551e-02,  1.4585e-02, -2.1397e-02,\n",
            "        -2.6228e-02, -2.5353e-02, -3.5191e-03, -2.5095e-02,  1.7022e-02,\n",
            "        -1.7454e-03, -2.0015e-02, -1.2144e-02,  1.0837e-03,  1.9384e-02,\n",
            "        -8.8426e-04, -6.7850e-03, -1.7019e-03,  3.1404e-02,  9.1087e-03,\n",
            "         3.3365e-02, -2.8981e-02,  2.1082e-02,  1.9944e-02, -2.8120e-02,\n",
            "        -6.6898e-05, -1.9246e-02, -2.6498e-02,  1.0200e-02,  1.2758e-02,\n",
            "         2.2010e-02,  1.6393e-02,  2.4603e-02,  2.0157e-02, -1.4805e-02,\n",
            "        -1.1993e-02, -2.3933e-02, -2.7800e-02, -2.4474e-02, -1.1442e-03,\n",
            "         1.9018e-02, -1.7169e-02, -3.5225e-03, -3.1606e-02, -3.5051e-02,\n",
            "        -2.2442e-02, -2.9475e-02, -2.9807e-02, -2.6068e-02, -2.3329e-02,\n",
            "         1.1143e-02,  5.1911e-03,  1.8503e-02, -3.3823e-02,  2.7020e-02,\n",
            "         3.0597e-02, -2.3050e-02,  1.9007e-02,  3.6266e-03, -4.4004e-03,\n",
            "        -5.1495e-03,  2.9148e-03, -5.1231e-03,  6.7284e-03,  3.2117e-02,\n",
            "        -2.2404e-02, -3.4449e-02,  2.4842e-02, -2.5273e-02,  2.5934e-02,\n",
            "         2.8402e-02,  1.6467e-02, -5.7265e-03, -3.3166e-03,  1.9256e-02,\n",
            "        -1.0744e-02,  2.7169e-03, -2.5390e-02, -3.5485e-02, -5.9718e-03,\n",
            "        -2.3635e-02, -1.0485e-02, -1.0855e-02,  1.8807e-03,  1.6473e-02,\n",
            "        -8.8703e-03, -8.0825e-03, -1.8448e-02,  3.5080e-02,  3.8773e-03,\n",
            "         2.6822e-02, -3.4248e-02,  1.8039e-02,  1.2316e-02, -3.1003e-02,\n",
            "        -1.9122e-02,  3.4425e-02, -1.6616e-02,  2.5755e-03, -1.1189e-02,\n",
            "         1.2061e-02, -1.0095e-02,  3.1290e-03, -3.3912e-02,  4.1633e-03,\n",
            "         3.4514e-02, -2.9848e-02, -1.2786e-03, -2.6206e-02, -6.2196e-04,\n",
            "        -3.4496e-03, -1.4168e-02, -1.6390e-02,  2.1078e-02, -1.2168e-02,\n",
            "         6.4577e-03, -1.2927e-02, -2.8320e-02,  2.3309e-02,  1.7285e-02,\n",
            "        -2.6562e-02, -2.5121e-02, -2.1875e-02, -2.6734e-02,  2.0724e-02,\n",
            "         1.0541e-03, -1.6706e-03,  3.5448e-02, -1.5362e-02, -3.4241e-02,\n",
            "         3.0730e-02,  6.4094e-03,  7.9554e-03,  7.2300e-03,  1.6039e-02,\n",
            "         1.3723e-03,  1.6224e-02, -1.5916e-02,  2.8555e-02, -3.0625e-02,\n",
            "        -3.4490e-02,  1.6177e-03, -1.6709e-02,  2.7840e-03,  2.6482e-02,\n",
            "         6.2678e-03, -2.8921e-03,  2.5779e-02,  2.2082e-02,  3.4483e-03,\n",
            "         3.1379e-02, -2.7494e-02,  1.8569e-02,  2.2949e-02,  2.7465e-02,\n",
            "        -2.1141e-02,  2.0281e-02,  1.1688e-02,  3.3248e-02, -3.4383e-02,\n",
            "         9.7176e-03,  1.0803e-02, -5.9248e-03,  3.9033e-03, -1.5641e-02,\n",
            "         3.2583e-02, -2.2214e-02, -3.1460e-02,  3.2935e-02, -1.0472e-03,\n",
            "        -4.0809e-03, -1.4675e-02,  3.2397e-02,  1.4276e-02,  3.0041e-03,\n",
            "        -1.7420e-02,  1.3335e-02,  2.2418e-02,  4.5710e-03, -4.7255e-03,\n",
            "         7.6541e-03, -8.9799e-03,  2.3672e-02, -1.8531e-02, -3.0709e-02,\n",
            "         3.3270e-04, -2.4736e-02, -5.0326e-03,  2.3047e-02,  3.0996e-02,\n",
            "         3.2670e-02, -8.5054e-03,  6.8630e-03, -2.2903e-02, -2.0330e-02,\n",
            "         1.4192e-02, -2.0823e-03,  2.4704e-02, -1.9067e-02, -1.6964e-02,\n",
            "        -1.2876e-02, -2.2079e-02, -3.1640e-02,  1.2242e-02, -1.0067e-02,\n",
            "         2.9860e-02, -1.1554e-02, -8.2108e-04,  1.6533e-02,  8.4561e-03,\n",
            "         6.8648e-03,  2.2675e-02, -9.4059e-03,  2.2256e-02, -3.9431e-03,\n",
            "         1.2214e-02,  1.3721e-02, -2.0203e-02, -1.3711e-02,  1.8045e-02,\n",
            "         3.1745e-02,  1.8310e-02, -3.2773e-02,  1.7770e-02, -2.7988e-02,\n",
            "        -2.9128e-02,  1.1459e-02, -3.4679e-02, -2.1966e-02,  5.6279e-03,\n",
            "        -9.4564e-03,  1.8518e-02,  1.1614e-02,  2.7827e-02,  1.7083e-02,\n",
            "        -1.9064e-02,  1.6248e-02,  7.5242e-03, -2.3943e-02, -2.4214e-03,\n",
            "         4.0508e-03,  3.3311e-02,  4.9637e-03, -2.7552e-02, -4.5139e-03,\n",
            "         1.3700e-02,  2.4686e-02, -1.5858e-02,  3.3344e-02, -2.0067e-02,\n",
            "         2.4483e-02,  3.8886e-03,  3.3184e-02, -1.8690e-02, -8.7665e-03,\n",
            "         2.6725e-02,  2.7433e-02,  2.7862e-02, -3.4593e-02,  2.7862e-02,\n",
            "         3.3578e-02,  7.2591e-03, -1.4077e-02,  5.1812e-04, -2.1725e-02,\n",
            "        -1.9816e-02, -5.7167e-03,  2.7477e-02, -1.5068e-02,  2.8162e-02,\n",
            "        -2.6176e-02, -9.3099e-04,  1.9949e-02,  1.0667e-02,  5.2716e-04,\n",
            "         2.3571e-02, -3.4753e-02,  6.5406e-03,  9.4395e-03,  2.4562e-02,\n",
            "         5.8060e-03,  1.8119e-02,  1.8586e-02, -1.0482e-02,  1.4624e-02,\n",
            "         3.4700e-02, -1.9250e-02, -3.0860e-02, -3.0440e-02,  2.1649e-02,\n",
            "         4.4475e-03,  6.0888e-03,  1.6090e-02,  1.9966e-02,  2.1160e-02,\n",
            "        -1.6848e-02,  2.9002e-02,  2.0217e-02,  2.5276e-02,  1.1892e-02,\n",
            "        -1.2199e-02,  1.8166e-02,  3.9473e-03, -2.0800e-02, -1.0045e-02,\n",
            "         9.2179e-03, -1.2797e-02,  3.0444e-03,  2.2123e-02,  6.7589e-03,\n",
            "        -3.1607e-02, -3.1129e-02,  2.0240e-02,  2.3244e-03, -2.3545e-02,\n",
            "        -3.3237e-02, -3.5049e-02,  2.7234e-02, -2.9727e-02,  5.4246e-03,\n",
            "         1.7514e-02, -2.7654e-02,  3.2757e-02,  1.3248e-02,  6.5805e-03,\n",
            "        -2.1511e-02,  5.2669e-03, -1.7262e-02, -7.9474e-03,  3.1264e-03,\n",
            "        -3.2261e-03,  2.6249e-02, -2.8752e-02,  2.3470e-02,  1.8299e-02,\n",
            "        -7.0049e-03, -3.3137e-02,  1.1028e-02, -1.4535e-02, -1.5444e-02,\n",
            "         1.1578e-02, -3.2147e-02,  2.6106e-02, -1.1058e-02, -3.2540e-02,\n",
            "         1.6040e-02, -3.3682e-02, -3.5739e-03, -2.8764e-02,  9.6020e-03,\n",
            "        -2.6177e-02,  1.9318e-02,  3.9088e-03,  1.2652e-02, -1.9806e-02,\n",
            "        -2.6887e-02, -1.3852e-02, -1.7114e-03, -3.4971e-02,  2.0835e-02,\n",
            "        -3.4149e-02, -2.2170e-02,  1.7356e-03,  3.1420e-02, -1.5360e-02,\n",
            "         1.9054e-02,  1.3062e-02, -8.4654e-04,  1.7260e-03,  2.6838e-02,\n",
            "         3.5008e-02,  1.4633e-02, -2.7918e-02,  1.5240e-02, -2.6747e-02,\n",
            "        -1.9707e-02, -2.7133e-03,  2.0297e-02,  2.0471e-02,  1.2204e-02,\n",
            "        -1.9261e-02, -5.8882e-03,  3.4389e-03, -2.4738e-02, -1.5611e-02,\n",
            "        -2.8364e-02, -1.1583e-02], device='cuda:0', requires_grad=True) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Couches du modèle\n",
        "\n",
        "Décomposons les couches du modèle FashionMNIST. Pour l'illustrer, nous\n",
        "prenons un mini-lot de 3 images de taille **28x28** et voyons ce qu'il en advient lorsque nous le faisons passer dans le réseau."
      ],
      "metadata": {
        "id": "l4jKy7x5eBDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p12fyv4D6EJl",
        "outputId": "97261d4d-05be-4ad7-8408-20204ca4bb0a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Flatten\n",
        "\n",
        "Nous initialisons la couche `nn.Flatten` pour convertir chaque image 2D 28x28 en un tableau contigu de 784 valeurs de pixels, c'est-à-dire que la dimension du minibatch (à dim=0) est maintenue. Chacun des pixels est transmis à la couche d'entrée du réseau neuronal.  \n",
        "\n",
        "<img alt=\"Diagramme montrant comment les pixels d'une image sont aplatis.\" src=\"../images/4-model-3.png\" />"
      ],
      "metadata": {
        "id": "1ni349sQeBAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r_53e6t6N5d",
        "outputId": "17ebb91c-97da-4823-f7ff-12b830df76a0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn. Linear\n",
        "\n",
        "La couche linéaire est un module qui applique une transformation linéaire à l'entrée à l'aide des poids et des biais qu'il a stockés. La valeur en niveaux de gris de chaque pixel de la couche d'entrée sera connectée aux neurones de la couche cachée pour le calcul. Le calcul utilisé pour la transformation est ${{poids * entrée + biais}} $."
      ],
      "metadata": {
        "id": "qKn7Mg4deA9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkqn9E9W6V5b",
        "outputId": "1518c9a0-0e08-4f80-a4ac-aa337ea1728a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.ReLU\n",
        "\n",
        "Les activations non linéaires créent les correspondances complexes entre les entrées et les sorties du modèle.\n",
        "Elles sont appliquées après les transformations linéaires pour introduire la *non-linéarité*, ce qui permet aux réseaux neuronaux d'apprendre une grande variété de phénomènes.\n",
        "Dans ce modèle, nous utilisons `nn.ReLU` entre nos couches linéaires, mais il existe d'autres activations pour introduire la non-linéarité dans votre modèle.\n",
        "\n",
        "La fonction d'activation ReLU prend la sortie du calcul de la couche linéaire et remplace les valeurs négatives par des zéros.\n",
        "\n",
        "Sortie linéaire : ${ x = {poids * entrée + biais}} $.  \n",
        "ReLU :\n",
        "$f(x)=\n",
        "\\begin{cases}\n",
        "    0, & \\text{if } x < 0\\\\\n",
        "    x, & \\text{if } x\\geq 0\\\\\n",
        "\\end{cases}\n",
        "$"
      ],
      "metadata": {
        "id": "D2hDYxbReA7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0c8Kav_6eb6",
        "outputId": "ef46fd52-508a-4544-ed7a-6a06bc57a6c2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.4520, -0.4698, -0.3244,  0.5366, -0.2308, -0.1813,  0.3536,  0.0967,\n",
            "         -0.1782,  0.2519,  0.0278,  0.5690,  0.0106, -0.1746, -0.1091,  0.5944,\n",
            "          0.1992,  0.2681,  0.2368, -0.1746],\n",
            "        [ 0.0608, -0.3350, -0.5382,  0.3808, -0.1126, -0.6103,  0.4189,  0.4752,\n",
            "         -0.2502,  0.3595,  0.3911,  0.6121,  0.2240,  0.1250,  0.2595,  0.5182,\n",
            "          0.0250,  0.1874,  0.1373, -0.3256],\n",
            "        [ 0.1822, -0.5051, -0.3464, -0.1076, -0.4147, -0.2408,  0.5895,  0.1618,\n",
            "         -0.4513,  0.4112, -0.1374,  0.6789, -0.2847, -0.0277, -0.0767,  0.4823,\n",
            "          0.0047,  0.3315,  0.0815,  0.0839]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.4520, 0.0000, 0.0000, 0.5366, 0.0000, 0.0000, 0.3536, 0.0967, 0.0000,\n",
            "         0.2519, 0.0278, 0.5690, 0.0106, 0.0000, 0.0000, 0.5944, 0.1992, 0.2681,\n",
            "         0.2368, 0.0000],\n",
            "        [0.0608, 0.0000, 0.0000, 0.3808, 0.0000, 0.0000, 0.4189, 0.4752, 0.0000,\n",
            "         0.3595, 0.3911, 0.6121, 0.2240, 0.1250, 0.2595, 0.5182, 0.0250, 0.1874,\n",
            "         0.1373, 0.0000],\n",
            "        [0.1822, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5895, 0.1618, 0.0000,\n",
            "         0.4112, 0.0000, 0.6789, 0.0000, 0.0000, 0.0000, 0.4823, 0.0047, 0.3315,\n",
            "         0.0815, 0.0839]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Sequential\n",
        "\n",
        "`nn.Sequential` est un conteneur ordonné de modules. Les données sont transmises à tous les modules dans l'ordre défini. Vous pouvez utiliser\n",
        "des conteneurs séquentiels pour mettre en place un réseau rapide comme `seq_modules`."
      ],
      "metadata": {
        "id": "y_gdDtrFeA4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ],
      "metadata": {
        "id": "Z7mD-rFH6vFU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Softmax\n",
        "\n",
        "La dernière couche linéaire du réseau neuronal renvoie des `logits` (les valeurs brutes dans \\[`-infty`, `infty`]), qui sont transmis au module\n",
        "`nn.Softmax`. La fonction d'activation Softmax est utilisée pour calculer la probabilité de la sortie du réseau neuronal. Elle n'est utilisée que sur la couche de sortie d'un réseau neuronal. Les résultats sont mis à l'échelle des valeurs \\[0, 1\\] représentant les densités prédites par le modèle pour chaque classe. Le paramètre `dim` indique la dimension sur laquelle la somme des valeurs des résultats doit être égale à 1. Le nœud ayant la probabilité la plus élevée prédit la sortie souhaitée.\n"
      ],
      "metadata": {
        "id": "trYqS1oHeA1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ],
      "metadata": {
        "id": "wInEHap_65I1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paramètres du modèle\n",
        "\n",
        "De nombreuses couches d'un réseau neuronal sont *paramétrées*, c'est-à-dire que les couches ont des poids et des biais associés qui sont optimisés au cours de l'entrainement.\n",
        "La sous-classe `nn.Module` suit automatiquement tous les champs définis à l'intérieur de l'objet modèle, et rend toutes les couches optimisées pendant l'entrainement. Automatiquement tous les champs définis dans l'objet de votre modèle et rend tous les paramètres\n",
        "accessibles en utilisant les méthodes `parameters()` ou `named_parameters()` de votre modèle.\n",
        "\n",
        "Dans cet exemple, nous itérons sur chaque paramètre, et nous imprimons sa taille ainsi qu'un aperçu de ses valeurs."
      ],
      "metadata": {
        "id": "NxT3YLebeAyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model structure: \", model, \"\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NseGcOUD7B8_",
        "outputId": "18e8f6b8-9c6a-41bc-91a5-a8a7bd37e272"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure:  NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ") \n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0175,  0.0336,  0.0039,  ...,  0.0136,  0.0038,  0.0198],\n",
            "        [-0.0314, -0.0196, -0.0240,  ..., -0.0143, -0.0110, -0.0244]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0240,  0.0104], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0150,  0.0383,  0.0194,  ..., -0.0082,  0.0055, -0.0032],\n",
            "        [ 0.0100,  0.0330,  0.0164,  ...,  0.0172,  0.0214,  0.0394]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0428, -0.0039], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0420,  0.0391, -0.0177,  ...,  0.0107,  0.0337, -0.0166],\n",
            "        [-0.0190, -0.0206, -0.0187,  ...,  0.0033,  0.0223,  0.0174]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0120, -0.0292], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Différenciation automatique avec ``torch.autograd``\n",
        "\n",
        "Lors de l'apprentissage des réseaux neuronaux, l'algorithme le plus fréquemment utilisé est le **backpropagation (rétropropagation)**. Dans cet algorithme, les paramètres (poids du modèle) sont ajustés en fonction du **gradient** de la fonction de perte par rapport au paramètre donné. La fonction de perte calcule la différence entre la sortie attendue et la sortie réelle produite par un réseau neuronal. L'objectif est de rapprocher le plus possible le résultat de la fonction de perte de zéro. L'algorithme parcourt le réseau neuronal à l'inverse pour ajuster les poids et les biais afin de réentraîner le modèle. C'est pourquoi on parle de rétropropagation. Ce processus de rétro-propagation et de réentraînement du modèle au fil du temps pour réduire la perte à 0 est appelé descente de gradient.\n",
        "\n",
        "Pour calculer ces gradients, PyTorch dispose d'un moteur de différenciation intégré appelé `torch.autograd`. Il permet le calcul automatique du gradient pour n'importe quel graphe de calcul.\n",
        "\n",
        "Considérons le plus simple des réseaux neuronaux à une couche, avec l'entrée `x`, les paramètres `w` et `b`, et une certaine fonction de perte. Il peut être défini dans\n",
        "PyTorch de la manière suivante :"
      ],
      "metadata": {
        "id": "3tODy59CeAvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "\n",
        "x = torch.ones(5)  # input tensor\n",
        "y = torch.zeros(3)  # expected output\n",
        "w = torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "z = torch.matmul(x, w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ],
      "metadata": {
        "id": "3lJYCD4U7PWS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tenseurs, fonctions et graphes de calcul\n",
        "\n",
        "Dans ce réseau, `w` et `b` sont des **paramètres** que nous devons optimiser. Par conséquent, nous devons être en mesure de calculer les gradients de la fonction de perte par rapport à ces variables.\n",
        "Pour ce faire, nous définissons la propriété `requires_grad` de ces tenseurs.\n",
        "\n",
        "> **Note:** Vous pouvez définir la valeur de `requires_grad` lors de la création d'un tenseur, ou plus tard en utilisant la méthode `x.requires_grad_(True)`.\n",
        "\n",
        "Une fonction que nous appliquons aux tenseurs pour construire des graphes de calcul est un objet de la classe `Fonction`. Cet objet sait comment\n",
        "calculer la fonction dans la direction *avant*, et aussi comment calculer sa dérivée pendant l'étape de *propagation en arrière*. Une référence à la fonction de rétropropagation est stockée dans la propriété `grad_fn` d'un tenseur."
      ],
      "metadata": {
        "id": "_bzq7kKAeAsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Gradient function for z =',z.grad_fn)\n",
        "print('Gradient function for loss =', loss.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Him6mRK7ZrU",
        "outputId": "ae38b169-d360-4c10-e2b3-156593e55ff9"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7c426ccbb790>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7c426ccbace0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calcul des gradients\n",
        "\n",
        "Pour optimiser les poids des paramètres du réseau neuronal, nous devons\n",
        "calculer les dérivées de notre fonction de perte par rapport aux paramètres,\n",
        "à savoir, nous avons besoin de $\\frac{\\partial loss}{\\partial w}$ et\n",
        "$\\frac{\\partial loss}{\\partial b}$ sous certaines valeurs fixes de\n",
        "`x` et `y`. Pour calculer ces dérivées, nous appelons\n",
        "`loss.backward()`, puis nous récupérons les valeurs de `w.grad` et\n",
        "`b.grad` :"
      ],
      "metadata": {
        "id": "8nw4_4jKeApy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gpt0HD77kaG",
        "outputId": "17fcd239-eb3a-48c1-e7cd-e9bf97f2c1c2"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2407, 0.2255, 0.2720],\n",
            "        [0.2407, 0.2255, 0.2720],\n",
            "        [0.2407, 0.2255, 0.2720],\n",
            "        [0.2407, 0.2255, 0.2720],\n",
            "        [0.2407, 0.2255, 0.2720]])\n",
            "tensor([0.2407, 0.2255, 0.2720])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Note:** Nous ne pouvons obtenir les propriétés `grad` que pour les noeuds feuilles du graphe de calcul dont la propriété `requires_grad` est fixée à `True`. Pour tous les autres noeuds de notre graphe, les gradients ne seront pas disponibles.\n",
        "\n",
        "## Désactiver le suivi du gradient\n",
        "\n",
        "Par défaut, tous les tenseurs avec `requires_grad=True` suivent leur historique de calcul et supportent le calcul de gradient. Cependant, il y a des cas où nous n'avons pas besoin de faire cela, par exemple, lorsque nous avons entraîné le modèle et que nous voulons juste l'appliquer à des données d'entrée, c'est-à-dire que nous voulons seulement faire des calculs *en avant* à travers le réseau. Nous pouvons arrêter le suivi des calculs en entourant notre code de calcul d'un bloc `torch.no_grad()` :"
      ],
      "metadata": {
        "id": "EH97PMnCeAm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "    z = torch.matmul(x, w)+b\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi71Y26-7zyb",
        "outputId": "58ba3589-ef42-42ac-fb97-efb0ba96109b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Une autre façon d'obtenir le même résultat est d'utiliser la méthode ``detach()`` sur le tenseur.\n",
        "sur le tenseur :"
      ],
      "metadata": {
        "id": "uwKf_yKeeAjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, w)+b\n",
        "z_det = z.detach()\n",
        "print(z_det.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNTA-mKv7-MN",
        "outputId": "ac7e9741-aefb-4c9d-fc59-983a945b33d6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il existe plusieurs raisons de désactiver le suivi du gradient :\n",
        "  - Pour marquer certains paramètres de votre réseau neuronal comme **paramètres gelés**. Il s'agit d'un scénario très courant pour la mise au point d'un réseau pré-entrainé.\n",
        "  - Pour **accélérer les calculs** lorsque vous n'effectuez qu'une passe avant, car les calculs sur les tenseurs qui ne suivent pas les gradients sont plus efficaces."
      ],
      "metadata": {
        "id": "gduI-9wkeAgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En savoir plus sur les graphes informatiques\n",
        "----------------------------\n",
        "Conceptuellement, autograd conserve un enregistrement des données (tenseurs) et de toutes les opérations exécutées (ainsi que des nouveaux tenseurs résultants) dans un graphe acyclique dirigé (DAG) constitué d'objets [Function](https://pytorch.org/docs/stable/autograd.html#torch.autograd.Function)\n",
        "objets. Dans ce DAG, les feuilles sont les tenseurs d'entrée et les racines sont les tenseurs de sortie. En traçant ce graphe des racines aux feuilles, vous pouvez\n",
        "calculer automatiquement les gradients à l'aide de la règle de la chaîne.\n",
        "\n",
        "Dans une passe en avant, autograd fait deux choses simultanément :\n",
        "\n",
        "- il exécute l'opération demandée pour calculer le tenseur résultant, et\n",
        "- maintient la *fonction de gradient* de l'opération dans le DAG.\n",
        "\n",
        "La passe arrière démarre quand `.backward()` est appelé sur la racine du DAG. Ensuite, `autograd` :\n",
        "\n",
        "- calcule les gradients de chaque `.grad_fn`,\n",
        "- les accumule dans l'attribut `.grad` du tenseur correspondant, et\n",
        "- en utilisant la règle de la chaîne, se propage jusqu'aux tenseurs feuilles.\n",
        "\n",
        "**Les DAGs sont dynamiques dans PyTorch**\n",
        "\n",
        "  Une chose importante à noter est que le graphe est recréé à partir de zéro ; après chaque appel à `.backward()`, autograd commence à remplir un nouveau graphe. C'est exactement ce qui vous permet d'utiliser des instructions de flux de contrôle dans votre modèle ; vous pouvez changer la forme, la taille et les opérations à chaque itération si nécessaire."
      ],
      "metadata": {
        "id": "e2ulQm7reAax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimisation des paramètres du modèle\n",
        "\n",
        "Maintenant que nous disposons d'un modèle et de données, il est temps d'entraîner, de valider et de tester notre modèle en optimisant ses paramètres sur nos données. L'apprentissage d'un modèle est un processus itératif ; à chaque itération (*époch*). Le modèle fait une supposition sur la sortie, calcule l'erreur dans sa supposition (*perte*), collecte les dérivées de l'erreur par rapport à ses paramètres (comme nous l'avons vu dans le module précédent), et **optimise** ces paramètres à l'aide de la descente de gradient.\n",
        "\n",
        "## Code prérequis\n",
        "\n",
        "Nous allons charger le code des modules précédents sur **Datasets & DataLoaders** et **Build Model**."
      ],
      "metadata": {
        "id": "on3pkVrIeARj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ],
      "metadata": {
        "id": "5FGJxafGZ4ZY"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Définition des hyperparamètres\n",
        "\n",
        "Les hyperparamètres sont des paramètres ajustables qui vous permettent de contrôler le processus d'optimisation du modèle.\n",
        "Différentes valeurs d'hyperparamètres peuvent avoir un impact sur l'apprentissage du modèle et le niveau de précision.\n",
        "\n",
        "Nous définissons les hyperparamètres suivants pour l'entrainement:\n",
        " - **Nombre d'époques** - le nombre de fois que l'ensemble des données d'apprentissage passe par le réseau.\n",
        " - **batch size** - taille du lot.\n",
        " - **Taux d'apprentissage** - la taille des étapes auxquelles le modèle correspond lorsqu'il recherche les meilleurs poids qui produiront une plus grande précision du modèle. Des valeurs plus petites signifient que le modèle mettra plus de temps à trouver les meilleurs poids. Des valeurs plus élevées peuvent conduire le modèle à dépasser et à manquer les meilleurs poids, ce qui entraîne un comportement imprévisible au cours de l'apprentissage."
      ],
      "metadata": {
        "id": "F-WJlBjT-nXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "1NOckGXL-sJc"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ajouter une boucle d'optimisation\n",
        "\n",
        "Une fois que nous avons défini nos hyperparamètres, nous pouvons entraîner et optimiser notre modèle à l'aide d'une boucle d'optimisation. Chaque itération de la boucle d'optimisation est appelée **époque (epoch)**.\n",
        "\n",
        "Chaque époque se compose de deux parties principales :\n",
        " - **La boucle d'entraînement** - itère sur l'ensemble des données d'entraînement et tente de converger vers les paramètres optimaux.\n",
        " - **La boucle de validation/test** - itère sur l'ensemble de données de test pour vérifier si les performances du modèle s'améliorent.\n",
        "\n",
        "Examinons quelques-uns des concepts utilisés dans la boucle d'apprentissage. Passez à l'étape suivante pour voir l'implémentation complète de la boucle d'optimisation.\n",
        "\n",
        "### Ajouter une fonction de perte\n",
        "\n",
        "Lorsqu'on lui présente des données d'entraînement, notre réseau non entraîné est susceptible de ne pas donner la bonne réponse. Une **fonction de perte** mesure le degré de dissimilarité d'un résultat obtenu par rapport à la valeur cible, et c'est la fonction de perte que nous voulons minimiser pendant la formation. Pour calculer la perte, nous faisons une prédiction en utilisant les entrées de notre échantillon de données donné et nous la comparons à la véritable valeur de l'étiquette des données.\n",
        "\n",
        "Les fonctions de perte les plus courantes sont les suivantes\n",
        "\n",
        "- `nn.MSELoss` (Mean Square Error) utilisée pour les tâches de régression\n",
        "- `nn.NLLLoss` (Negative Log Likelihood) utilisée pour la classification\n",
        "- `nn.CrossEntropyLoss` combine `nn.LogSoftmax` et `nn.NLLLoss`.\n",
        "\n",
        "Nous passons les logits de sortie de notre modèle à `nn.CrossEntropyLoss`, qui va normaliser les logits et calculer l'erreur de prédiction."
      ],
      "metadata": {
        "id": "M_cc20Qr-nUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "_dbGpws1-6xX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passe d'optimisation\n",
        "\n",
        "L'optimisation est le processus d'ajustement des paramètres du modèle afin de réduire l'erreur du modèle à chaque étape de l'apprentissage. **Les algorithmes d'optimisation** définissent la manière dont ce processus est exécuté (dans cet exemple, nous utilisons la *descente de gradient stochastique*).\n",
        "Toute la logique d'optimisation est encapsulée dans l'objet `optimizer`. Ici, nous utilisons l'optimiseur SGD ;\n",
        "Il existe de nombreux optimiseurs différents dans PyTorch, tels que `ADAM` et `RMSProp`, qui sont adaptés à différents types de modèles et de données.\n",
        "\n",
        "Nous initialisons l'optimiseur en enregistrant les paramètres du modèle qui doivent être entraînés, et en passant l'hyperparamètre du taux d'apprentissage."
      ],
      "metadata": {
        "id": "q_ldw3xq-nRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Vi3loPGs_D2p"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A l'intérieur de la boucle d'apprentissage, l'optimisation se fait en trois étapes :\n",
        " * Appeler `optimizer.zero_grad()` pour réinitialiser les gradients des paramètres du modèle. Les gradients s'additionnent par défaut ; pour éviter le double comptage, nous les mettons explicitement à zéro à chaque itération.\n",
        " * Propager la perte de la prediction en faisant appel à `loss.backwards()`. PyTorch dépose les gradients de la perte par rapport à chaque paramètre.\n",
        " * Une fois que nous avons nos gradients, nous appelons `optimizer.step()` pour ajuster les paramètres par les gradients collectés dans la passe arrière."
      ],
      "metadata": {
        "id": "ZL-iOF4t-nPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implémentation complète\n",
        "\n",
        "Nous définissons une fonction `train_loop` qui boucle notre code d'optimisation, et une fonction `test_loop` qui évalue la performance du modèle par rapport à nos données de test.\n",
        "qui évalue les performances du modèle par rapport à nos données de test."
      ],
      "metadata": {
        "id": "pNEWmJlm-nMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "dQRDDzubAfPJ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous initialisons la fonction de perte et l'optimiseur, et nous les passons à `train_loop` et `test_loop`.\n",
        "N'hésitez pas à augmenter le nombre d'époques pour suivre l'amélioration des performances du modèle."
      ],
      "metadata": {
        "id": "8suadX1e-nJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hepz0eVsD1d-",
        "outputId": "2efae018-b9a8-4090-b40b-668275ba110f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.306868  [    0/60000]\n",
            "loss: 2.302304  [ 6400/60000]\n",
            "loss: 2.288317  [12800/60000]\n",
            "loss: 2.281337  [19200/60000]\n",
            "loss: 2.292015  [25600/60000]\n",
            "loss: 2.258157  [32000/60000]\n",
            "loss: 2.267298  [38400/60000]\n",
            "loss: 2.254184  [44800/60000]\n",
            "loss: 2.235031  [51200/60000]\n",
            "loss: 2.222592  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 37.4%, Avg loss: 0.035040 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.240239  [    0/60000]\n",
            "loss: 2.250130  [ 6400/60000]\n",
            "loss: 2.204033  [12800/60000]\n",
            "loss: 2.189701  [19200/60000]\n",
            "loss: 2.238555  [25600/60000]\n",
            "loss: 2.171520  [32000/60000]\n",
            "loss: 2.185169  [38400/60000]\n",
            "loss: 2.163238  [44800/60000]\n",
            "loss: 2.128619  [51200/60000]\n",
            "loss: 2.112451  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 47.8%, Avg loss: 0.033362 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.151102  [    0/60000]\n",
            "loss: 2.170022  [ 6400/60000]\n",
            "loss: 2.077194  [12800/60000]\n",
            "loss: 2.044783  [19200/60000]\n",
            "loss: 2.152618  [25600/60000]\n",
            "loss: 2.046684  [32000/60000]\n",
            "loss: 2.048615  [38400/60000]\n",
            "loss: 2.026174  [44800/60000]\n",
            "loss: 1.967756  [51200/60000]\n",
            "loss: 1.921019  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 47.0%, Avg loss: 0.030705 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.007174  [    0/60000]\n",
            "loss: 2.038903  [ 6400/60000]\n",
            "loss: 1.880338  [12800/60000]\n",
            "loss: 1.827103  [19200/60000]\n",
            "loss: 2.031887  [25600/60000]\n",
            "loss: 1.885247  [32000/60000]\n",
            "loss: 1.858807  [38400/60000]\n",
            "loss: 1.868486  [44800/60000]\n",
            "loss: 1.789751  [51200/60000]\n",
            "loss: 1.697060  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 46.7%, Avg loss: 0.027876 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.854740  [    0/60000]\n",
            "loss: 1.906801  [ 6400/60000]\n",
            "loss: 1.696530  [12800/60000]\n",
            "loss: 1.628775  [19200/60000]\n",
            "loss: 1.927376  [25600/60000]\n",
            "loss: 1.750548  [32000/60000]\n",
            "loss: 1.711661  [38400/60000]\n",
            "loss: 1.748866  [44800/60000]\n",
            "loss: 1.655752  [51200/60000]\n",
            "loss: 1.544137  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 49.4%, Avg loss: 0.025815 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.738102  [    0/60000]\n",
            "loss: 1.805316  [ 6400/60000]\n",
            "loss: 1.558060  [12800/60000]\n",
            "loss: 1.494318  [19200/60000]\n",
            "loss: 1.826844  [25600/60000]\n",
            "loss: 1.645656  [32000/60000]\n",
            "loss: 1.608649  [38400/60000]\n",
            "loss: 1.656516  [44800/60000]\n",
            "loss: 1.553394  [51200/60000]\n",
            "loss: 1.444794  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 51.9%, Avg loss: 0.024275 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.642002  [    0/60000]\n",
            "loss: 1.725809  [ 6400/60000]\n",
            "loss: 1.449080  [12800/60000]\n",
            "loss: 1.398817  [19200/60000]\n",
            "loss: 1.735591  [25600/60000]\n",
            "loss: 1.556667  [32000/60000]\n",
            "loss: 1.529289  [38400/60000]\n",
            "loss: 1.579421  [44800/60000]\n",
            "loss: 1.473183  [51200/60000]\n",
            "loss: 1.369901  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 53.6%, Avg loss: 0.023051 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.558487  [    0/60000]\n",
            "loss: 1.661214  [ 6400/60000]\n",
            "loss: 1.360887  [12800/60000]\n",
            "loss: 1.324293  [19200/60000]\n",
            "loss: 1.658116  [25600/60000]\n",
            "loss: 1.479421  [32000/60000]\n",
            "loss: 1.464246  [38400/60000]\n",
            "loss: 1.515669  [44800/60000]\n",
            "loss: 1.407825  [51200/60000]\n",
            "loss: 1.310255  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 54.4%, Avg loss: 0.022052 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.485049  [    0/60000]\n",
            "loss: 1.603404  [ 6400/60000]\n",
            "loss: 1.288423  [12800/60000]\n",
            "loss: 1.260221  [19200/60000]\n",
            "loss: 1.595063  [25600/60000]\n",
            "loss: 1.413458  [32000/60000]\n",
            "loss: 1.410442  [38400/60000]\n",
            "loss: 1.464825  [44800/60000]\n",
            "loss: 1.352875  [51200/60000]\n",
            "loss: 1.262150  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 55.5%, Avg loss: 0.021232 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.421316  [    0/60000]\n",
            "loss: 1.555356  [ 6400/60000]\n",
            "loss: 1.228097  [12800/60000]\n",
            "loss: 1.206828  [19200/60000]\n",
            "loss: 1.544521  [25600/60000]\n",
            "loss: 1.357647  [32000/60000]\n",
            "loss: 1.365999  [38400/60000]\n",
            "loss: 1.423440  [44800/60000]\n",
            "loss: 1.306866  [51200/60000]\n",
            "loss: 1.224360  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 56.1%, Avg loss: 0.020565 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous avez peut-être remarqué que le modèle n'est pas très bon au départ (ce n'est pas grave !). Essayez de faire tourner la boucle pour plus d'\"epochs\" ou d'ajuster le \"learning_rate\" à un nombre plus grand. Il se peut aussi que la configuration du modèle que nous avons choisie ne soit pas optimale pour ce type de problème (ce n'est pas le cas).\n"
      ],
      "metadata": {
        "id": "blapUaTU-nGf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sauvegarde des modèles\n",
        "-------------\n",
        "\n",
        "Lorsque vous êtes satisfait des performances du modèle, vous pouvez utiliser `torch.save` pour le sauvegarder. Les modèles PyTorch stockent les paramètres appris dans un dictionnaire d'état interne, appelé `state_dict`. Ils peuvent être persistés avec la méthode `torch.save` :"
      ],
      "metadata": {
        "id": "onn9zD6b-nDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"data/model.pth\")\n",
        "\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SRmznFcFbqV",
        "outputId": "0aeaf521-f599-44eb-f043-7e4f8b63bee8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Charger le modèle\n",
        "\n",
        "Installtion des bibliotheques requises"
      ],
      "metadata": {
        "id": "mJ62HX86-nAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmw0HxbUIxjY",
        "outputId": "26bc82bc-22f8-4c1b-edf1-610939b805a8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.16.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import onnxruntime\n",
        "from torch import nn\n",
        "import torch.onnx as onnx\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "zclOzjpFHqdO"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour charger le modèle, nous définissons la classe de modèle qui contient l'état et les paramètres du réseau neuronal utilisé pour entrainer le modèle."
      ],
      "metadata": {
        "id": "gZEvDyRK-m90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "OyL5Df-OK2f4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lors du chargement des poids du modèle, nous devons d'abord instancier la classe de modèle, car elle définit la structure d'un réseau. Ensuite, nous chargeons les paramètres à l'aide de la méthode `load_state_dict()`."
      ],
      "metadata": {
        "id": "5QT03LO7-m68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load('data/model.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EoF29z9LAYK",
        "outputId": "5f0421a8-357e-439b-ed3d-fd5572428b19"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "    (5): ReLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Note:** Assurez-vous d'appeler la méthode `model.eval()` avant l'inférence pour mettre les couches d'exclusion (dropout) et de normalisation par lots (batch norm) en mode d'évaluation. Sinon, vous obtiendrez des résultats d'inférence incohérents."
      ],
      "metadata": {
        "id": "XfnvXA5J-m30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inférence de modèle\n",
        "\n",
        "Il est difficile d'optimiser un modèle pour qu'il fonctionne sur une variété de plates-formes et de langages de programmation. Il faut beaucoup de temps pour maximiser les performances à travers toutes les différentes combinaisons de frameworks et de matériel. Le runtime **Open Neural Network Exchange (ONNX)** offre une solution pour entrainer une fois et accélérer l'inférence sur n'importe quel matériel, cloud ou périphérique.\n",
        "\n",
        "ONNX est un format commun pris en charge par un certain nombre de fournisseurs pour partager des réseaux neuronaux et d'autres modèles d'apprentissage automatique. Vous pouvez utiliser le format ONNX pour effectuer une inférence sur votre modèle dans d'autres langages de programmation et frameworks tels que Java, JavaScript, C# et ML.NET."
      ],
      "metadata": {
        "id": "TiIUxTO_LIxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporter le modèle vers ONNX\n",
        "\n",
        "PyTorch dispose également d'un support natif pour l'exportation vers ONNX. Etant donné la nature dynamique du graphe d'exécution de PyTorch, le processus d'exportation doit traverser le graphe d'exécution pour produire un modèle ONNX persistant. Pour cette raison, une variable de test de la taille appropriée doit être passée à la routine d'exportation (dans notre cas, nous allons créer un tenseur zéro fictif de la bonne taille.  Vous pouvez obtenir la taille à partir de la fonction `shape` sur votre jeu de données d'apprentissage avec `tensor.shape`) :"
      ],
      "metadata": {
        "id": "7Y0liHHxLIuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.zeros((1,28,28))\n",
        "onnx_model = 'data/model.onnx'\n",
        "onnx.export(model, input_image, onnx_model)"
      ],
      "metadata": {
        "id": "e0YudlKiLXVW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous utiliserons notre ensemble de données de test comme échantillon de données pour l'inférence du modèle ONNX afin de faire des prédictions."
      ],
      "metadata": {
        "id": "pOPIkUpZLIri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "x, y = test_data[0][0], test_data[0][1]"
      ],
      "metadata": {
        "id": "3uZgRd0EMZRV"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous créons une session d'inférence avec `onnxruntime.InferenceSession`. Pour inférer le modèle ONNX, appelez `run` et passez la liste des sorties que vous voulez retourner (laissez vide si vous les voulez toutes) et une carte des valeurs d'entrée. Le résultat est une liste de sorties."
      ],
      "metadata": {
        "id": "nKrfD-2aLIos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "session = onnxruntime.InferenceSession(onnx_model, None)\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "result = session.run([output_name], {input_name: x.numpy()})\n",
        "predicted, actual = classes[result[0][0].argmax(0)], classes[y]\n",
        "print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otZGqWKVMkSz",
        "outputId": "42922b85-5ada-43cf-8907-f3e1bb12e2af"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Sandal\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle ONNX vous permet d'exécuter l'inférence sur différentes plates-formes et dans différents langages de programmation."
      ],
      "metadata": {
        "id": "ZEm5NcRYLIlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cette unité passe en revue l'API pour les tâches courantes de l'apprentissage automatique. Reportez-vous aux liens de chaque section pour approfondir.\n",
        "\n",
        "## Travailler avec des données\n",
        "PyTorch possède deux primitives pour travailler avec des données : ``torch.utils.data.DataLoader`` et ``torch.utils.data.Dataset``. ``Dataset`` stocke les échantillons et leurs étiquettes correspondantes, et ``DataLoader`` enroule un itérable autour de ``Dataset``."
      ],
      "metadata": {
        "id": "tx3NZvICLIiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "suFlEluZNHrl"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch propose des bibliothèques spécifiques à un domaine comme `TorchText`, `TorchVision`, et `TorchAudio`, qui incluent toutes des jeux de données. Pour ce tutoriel, nous utiliserons un jeu de données TorchVision.\n",
        "\n",
        "Le module ``torchvision.datasets`` contient des objets ``Dataset`` pour de nombreux jeux de données de vision du monde réel, tels que CIFAR et COCO. Dans ce tutoriel, nous utiliserons le dataset **FashionMNIST**. Chaque ``Dataset`` de TorchVision inclut deux arguments : ``transform`` et ``target_transform`` pour modifier les échantillons et les étiquettes respectivement."
      ],
      "metadata": {
        "id": "x7UWbf_nNKn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "RtQswqS0NtLN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous passons le ``Dataset`` comme argument à ``DataLoader``. Celui-ci enveloppe un itérable sur notre jeu de données, et supporte la mise en lot automatique, l'échantillonnage, le mélange, et le chargement de données multiprocessus. Ici, nous définissons une taille de lot de 64, où chaque élément de l'itérable dataloader retournera un lot de 64 caractéristiques et étiquettes."
      ],
      "metadata": {
        "id": "WctFN2ndNKkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break\n",
        "\n",
        "# Display sample data\n",
        "figure = plt.figure(figsize=(10, 8))\n",
        "cols, rows = 5, 5\n",
        "for i in range(1, cols * rows + 1):\n",
        "    idx = torch.randint(len(test_data), size=(1,)).item()\n",
        "    img, label = test_data[idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "T18D946DN4Az",
        "outputId": "2e946052-108c-4c41-fd00-b016d3d56cb5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 25 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Création de modèles\n",
        "Pour définir un réseau neuronal dans PyTorch, nous créons une classe qui hérite de `nn.Module`. Nous définissons les couches du réseau dans la fonction `__init__` et spécifions comment les données passeront à travers le réseau dans la fonction ``forward``. Pour accélérer les opérations dans le réseau neuronal, nous le déplaçons vers le GPU s'il est disponible."
      ],
      "metadata": {
        "id": "sbHyGFBONKhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSoqESDaOERL",
        "outputId": "aec73c9d-2046-4134-9413-6dfcd944a4d5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimisation des paramètres du modèle\n",
        "Pour entraîner un modèle, nous avons besoin d'une fonction de perte et d'un optimiseur.  Nous utiliserons `nn.CrossEntropyLoss` pour la perte et `Stochastic Gradient Descent` pour l'optimisation."
      ],
      "metadata": {
        "id": "UZ8eUkJzNKeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "B-XDGwefPNu6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans une seule boucle d'apprentissage, le modèle fait des prédictions sur l'ensemble des données d'apprentissage (qui lui sont fournies par lots) et rétro-propage l'erreur de prédiction pour ajuster les paramètres du modèle."
      ],
      "metadata": {
        "id": "f3zD8oDiNKbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "O2uZPdFJPXWK"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons également vérifier les performances du modèle par rapport à l'ensemble de données de test pour nous assurer qu'il apprend."
      ],
      "metadata": {
        "id": "JWs33tAzNKYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "vsoRQij0PhTJ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le processus d'entrainement se déroule sur plusieurs itérations (*époques*). Au cours de chaque époque, le modèle apprend des paramètres qui lui permettent de faire de meilleures prédictions. Nous imprimons la précision et la perte du modèle à chaque époque ; nous aimerions voir la précision augmenter et la perte diminuer à chaque époque."
      ],
      "metadata": {
        "id": "7wDmRfxANKVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPLxhCFbPr3g",
        "outputId": "1c96cc98-8a39-49a5-d910-b6b14f52cd9a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.304143  [    0/60000]\n",
            "loss: 2.295089  [ 6400/60000]\n",
            "loss: 2.287698  [12800/60000]\n",
            "loss: 2.288141  [19200/60000]\n",
            "loss: 2.291366  [25600/60000]\n",
            "loss: 2.292116  [32000/60000]\n",
            "loss: 2.290787  [38400/60000]\n",
            "loss: 2.289249  [44800/60000]\n",
            "loss: 2.274554  [51200/60000]\n",
            "loss: 2.292720  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 30.7%, Avg loss: 0.035672 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.262474  [    0/60000]\n",
            "loss: 2.254426  [ 6400/60000]\n",
            "loss: 2.236782  [12800/60000]\n",
            "loss: 2.254334  [19200/60000]\n",
            "loss: 2.267371  [25600/60000]\n",
            "loss: 2.271662  [32000/60000]\n",
            "loss: 2.271303  [38400/60000]\n",
            "loss: 2.268336  [44800/60000]\n",
            "loss: 2.241397  [51200/60000]\n",
            "loss: 2.282161  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 30.8%, Avg loss: 0.035160 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.219392  [    0/60000]\n",
            "loss: 2.207433  [ 6400/60000]\n",
            "loss: 2.176809  [12800/60000]\n",
            "loss: 2.212300  [19200/60000]\n",
            "loss: 2.241279  [25600/60000]\n",
            "loss: 2.246385  [32000/60000]\n",
            "loss: 2.249456  [38400/60000]\n",
            "loss: 2.243386  [44800/60000]\n",
            "loss: 2.201934  [51200/60000]\n",
            "loss: 2.271643  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 30.4%, Avg loss: 0.034560 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.169668  [    0/60000]\n",
            "loss: 2.151510  [ 6400/60000]\n",
            "loss: 2.105657  [12800/60000]\n",
            "loss: 2.162536  [19200/60000]\n",
            "loss: 2.213632  [25600/60000]\n",
            "loss: 2.216170  [32000/60000]\n",
            "loss: 2.226145  [38400/60000]\n",
            "loss: 2.216183  [44800/60000]\n",
            "loss: 2.160531  [51200/60000]\n",
            "loss: 2.258895  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 30.8%, Avg loss: 0.033920 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.116903  [    0/60000]\n",
            "loss: 2.093521  [ 6400/60000]\n",
            "loss: 2.032371  [12800/60000]\n",
            "loss: 2.111400  [19200/60000]\n",
            "loss: 2.185157  [25600/60000]\n",
            "loss: 2.181292  [32000/60000]\n",
            "loss: 2.195190  [38400/60000]\n",
            "loss: 2.170077  [44800/60000]\n",
            "loss: 2.115929  [51200/60000]\n",
            "loss: 2.219607  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 32.4%, Avg loss: 0.032915 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.045389  [    0/60000]\n",
            "loss: 2.002953  [ 6400/60000]\n",
            "loss: 1.918326  [12800/60000]\n",
            "loss: 2.036828  [19200/60000]\n",
            "loss: 2.068365  [25600/60000]\n",
            "loss: 2.073889  [32000/60000]\n",
            "loss: 2.124947  [38400/60000]\n",
            "loss: 2.074920  [44800/60000]\n",
            "loss: 2.060016  [51200/60000]\n",
            "loss: 2.155261  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 41.4%, Avg loss: 0.031523 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.954446  [    0/60000]\n",
            "loss: 1.890995  [ 6400/60000]\n",
            "loss: 1.788049  [12800/60000]\n",
            "loss: 1.954564  [19200/60000]\n",
            "loss: 1.936747  [25600/60000]\n",
            "loss: 1.965480  [32000/60000]\n",
            "loss: 2.051239  [38400/60000]\n",
            "loss: 1.980203  [44800/60000]\n",
            "loss: 2.004491  [51200/60000]\n",
            "loss: 2.095993  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 39.6%, Avg loss: 0.030172 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.871170  [    0/60000]\n",
            "loss: 1.790688  [ 6400/60000]\n",
            "loss: 1.675882  [12800/60000]\n",
            "loss: 1.883010  [19200/60000]\n",
            "loss: 1.819856  [25600/60000]\n",
            "loss: 1.881139  [32000/60000]\n",
            "loss: 1.992041  [38400/60000]\n",
            "loss: 1.911047  [44800/60000]\n",
            "loss: 1.956170  [51200/60000]\n",
            "loss: 2.056270  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 40.1%, Avg loss: 0.029168 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.808890  [    0/60000]\n",
            "loss: 1.721789  [ 6400/60000]\n",
            "loss: 1.600669  [12800/60000]\n",
            "loss: 1.831103  [19200/60000]\n",
            "loss: 1.740018  [25600/60000]\n",
            "loss: 1.827373  [32000/60000]\n",
            "loss: 1.947381  [38400/60000]\n",
            "loss: 1.865244  [44800/60000]\n",
            "loss: 1.912831  [51200/60000]\n",
            "loss: 2.025098  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 41.0%, Avg loss: 0.028435 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.760406  [    0/60000]\n",
            "loss: 1.674278  [ 6400/60000]\n",
            "loss: 1.547782  [12800/60000]\n",
            "loss: 1.791248  [19200/60000]\n",
            "loss: 1.685631  [25600/60000]\n",
            "loss: 1.789408  [32000/60000]\n",
            "loss: 1.910302  [38400/60000]\n",
            "loss: 1.830604  [44800/60000]\n",
            "loss: 1.875142  [51200/60000]\n",
            "loss: 1.997996  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 41.9%, Avg loss: 0.027869 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.720430  [    0/60000]\n",
            "loss: 1.638561  [ 6400/60000]\n",
            "loss: 1.507035  [12800/60000]\n",
            "loss: 1.761205  [19200/60000]\n",
            "loss: 1.647785  [25600/60000]\n",
            "loss: 1.761819  [32000/60000]\n",
            "loss: 1.879692  [38400/60000]\n",
            "loss: 1.803207  [44800/60000]\n",
            "loss: 1.843197  [51200/60000]\n",
            "loss: 1.975435  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 42.5%, Avg loss: 0.027419 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.687158  [    0/60000]\n",
            "loss: 1.610487  [ 6400/60000]\n",
            "loss: 1.473773  [12800/60000]\n",
            "loss: 1.737629  [19200/60000]\n",
            "loss: 1.618415  [25600/60000]\n",
            "loss: 1.708998  [32000/60000]\n",
            "loss: 1.819915  [38400/60000]\n",
            "loss: 1.708864  [44800/60000]\n",
            "loss: 1.787360  [51200/60000]\n",
            "loss: 1.934585  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 47.1%, Avg loss: 0.026475 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.597093  [    0/60000]\n",
            "loss: 1.580469  [ 6400/60000]\n",
            "loss: 1.394527  [12800/60000]\n",
            "loss: 1.701453  [19200/60000]\n",
            "loss: 1.594472  [25600/60000]\n",
            "loss: 1.640796  [32000/60000]\n",
            "loss: 1.767315  [38400/60000]\n",
            "loss: 1.648686  [44800/60000]\n",
            "loss: 1.746342  [51200/60000]\n",
            "loss: 1.912845  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 48.8%, Avg loss: 0.025950 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.548764  [    0/60000]\n",
            "loss: 1.554406  [ 6400/60000]\n",
            "loss: 1.355161  [12800/60000]\n",
            "loss: 1.676048  [19200/60000]\n",
            "loss: 1.568144  [25600/60000]\n",
            "loss: 1.612388  [32000/60000]\n",
            "loss: 1.733588  [38400/60000]\n",
            "loss: 1.611575  [44800/60000]\n",
            "loss: 1.710865  [51200/60000]\n",
            "loss: 1.893425  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 49.5%, Avg loss: 0.025539 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.512011  [    0/60000]\n",
            "loss: 1.532959  [ 6400/60000]\n",
            "loss: 1.324775  [12800/60000]\n",
            "loss: 1.656717  [19200/60000]\n",
            "loss: 1.549929  [25600/60000]\n",
            "loss: 1.589957  [32000/60000]\n",
            "loss: 1.706018  [38400/60000]\n",
            "loss: 1.581691  [44800/60000]\n",
            "loss: 1.680956  [51200/60000]\n",
            "loss: 1.877521  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.0%, Avg loss: 0.025211 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Au début, la précision ne sera pas très bonne (ce n'est pas grave !). Essayez de faire tourner la boucle pour plus d'\"epochs\" ou d'ajuster le \"learning_rate\" à un nombre plus grand. Il se peut aussi que la configuration du modèle que nous avons choisie ne soit pas optimale pour ce type de problème (ce n'est pas le cas). Des cours ultérieurs approfondiront les formes de modèles qui fonctionnent pour les problèmes de vision."
      ],
      "metadata": {
        "id": "Jsj_Y-5hNKS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sauvegarde des modèles\n",
        "-------------\n",
        "Une façon courante de sauvegarder un modèle consiste à sérialiser le dictionnaire d'états internes (contenant les paramètres du modèle)."
      ],
      "metadata": {
        "id": "rgWC4LFBNKP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"data/model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlQH2B_zP_O4",
        "outputId": "b3c5eca4-7416-4ac5-a7d8-ab19aeaa4cc6"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chargement des modèles\n",
        "----------------------------\n",
        "\n",
        "Le processus de chargement d'un modèle consiste à recréer la structure du modèle et à y charger le dictionnaire d'états.\n",
        "le dictionnaire d'états."
      ],
      "metadata": {
        "id": "4X_4fmyyNKNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"data/model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmE2EXp1QL4I",
        "outputId": "529c96b0-1b7c-40b8-9804-5ccb3c32f55f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce modèle peut maintenant être utilisé pour faire des prévisions."
      ],
      "metadata": {
        "id": "DxxLPUm4NKKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1E7DeliQU6R",
        "outputId": "4c5c22e1-2eab-4117-91e7-68bcc0e13a61"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    }
  ]
}